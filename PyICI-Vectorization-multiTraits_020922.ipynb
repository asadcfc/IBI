{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IBI implementation in python: Developed by Jinling Liu 12/26/2021\n",
    "### Can be applied to multiple traits or single trait\n",
    "### 02-09-22 updated the function of lgM_cal_1 so it can either calculate using topGD or sGD, with a flag of \"use_topGD\" before that function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2,venn2_circles\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import fisher_exact\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_traitsF (traitsF):  ### read the .csv file with traits (subjects_row x traits_column)\n",
    "    traits = pd.read_csv(traitsF,index_col = 0) # make sure the subIDs become the index column; as default, column names are inferred from the first line of the file\n",
    "    subIDs = list(traits.index)\n",
    "    traitIDs = traits.columns\n",
    "    traits = np.array(traits,dtype=np.int16)\n",
    "    \n",
    "    return (subIDs, traitIDs, traits) # list, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_variantsF (variantsF):## read the large genomic file (row_SNPs x column_subjects) line by line\n",
    "    header = True\n",
    "    variants = []\n",
    "    with open(variantsF) as f:\n",
    "        for line in f: # go through each SNP\n",
    "            if header: # extract the head of subject IDs\n",
    "                subIDs = line.strip().split(',')\n",
    "                subIDs = list(subIDs[1:])\n",
    "                header = False\n",
    "                continue\n",
    "            line = line.strip().split(',') #vID = line[0] ,the variant ID; line1 = line[1:] ,the SNP state values for all the subjects\n",
    "            variants.append(line)\n",
    "    variants = np.array(variants)\n",
    "    varIDs = list(variants[:,0])\n",
    "    variants = variants[:,1:].astype(int)\n",
    "    A0 = np.ones(len(subIDs))\n",
    "    variants = np.row_stack((A0,variants))\n",
    "    varIDs.insert(0,'A0')\n",
    "    \n",
    "    return (subIDs, varIDs, variants) # list, list and array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_variantsF1 (variantsF):## read the large genomic file (row_SNPs x column_subjects) using pandas\n",
    "    df = pd.read_csv(variantsF,index_col = 0) # this will turn the first column of varIDs into index thus df.columns will only include subIDs\n",
    "    varIDs = list(df.index)\n",
    "    subIDs = list(int(x) for x in df.columns)\n",
    "    variants = np.array(df,dtype=np.int8) \n",
    "    A0 = np.ones(len(subIDs),dtype=np.int8)\n",
    "    variants = np.row_stack((A0,variants))\n",
    "    varIDs.insert(0,'A0')\n",
    "    df = pd.DataFrame(variants,index=varIDs,columns=subIDs,dtype=np.int8)\n",
    "    \n",
    "    return (subIDs, varIDs, variants, df) # list, list, array and dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DriverSearch (traits,variants): \n",
    "    ### Calcuate and return the lgM for all the drivers or any driver for any given population for multiple traits\n",
    "    ### Get the top/bottom GD and SD as well as their lgM; this can be done in the lgM_cal function so this function can stay the same \n",
    "    ### Get the nxk matrix of traits==0 and the nxk matrix of traits==1 (n,#subjects;k,#traits; thus capable of working with multipe traits)\n",
    "    ### if no individuals are in V0 group when the passed variants is [], the V0D0 counts as well as lgM will be 0; the max value/index are both turned as 0\n",
    "    ### no other SNPs have a constant value since those have been removed in the preprocessing step\n",
    "    bpMask0 = traits==0\n",
    "    bpMask0 = bpMask0.astype(np.int16)\n",
    "    d0 = np.sum(bpMask0)\n",
    "    bpMask1 = traits==1\n",
    "    bpMask1 = bpMask1.astype(np.int16)\n",
    "    d1 = np.sum(bpMask1)\n",
    "    snpMask0 = variants==0\n",
    "    snpMask0 = snpMask0.astype(np.int16)\n",
    "    snpMask1 = variants==1\n",
    "    snpMask1 = snpMask1.astype(np.int16)\n",
    "    ### Get the four mx1 vector as below: m is # of SNPs in the dataset; for each SNP, the corresponding 4 values \n",
    "    ### from the 4 vectors make up the 2x2 tables between SNP and hypertension\n",
    "    V0D0 = snpMask0@bpMask0 #snpMask0, variants_row x subjects_column\n",
    "    V1D0 = snpMask1@bpMask0 #bpMask0, subjects_row x traits_column\n",
    "    V0D1 = snpMask0@bpMask1\n",
    "    V1D1 = snpMask1@bpMask1\n",
    "    # Calculate the log Marginal LikelihooD for this particular SNP based on the collected counts and equation 5 in the worD file\n",
    "    # when j=0 (V=0)\n",
    "    lgM = scipy.special.loggamma(2.0) - scipy.special.loggamma(2.0+V0D1+V0D0)\n",
    "    lgM += scipy.special.loggamma(1.0+V0D0) - scipy.special.loggamma(1.0)\n",
    "    lgM += scipy.special.loggamma(1.0+V0D1) - scipy.special.loggamma(1.0)\n",
    "    # when j=1 (V=1)\n",
    "    lgM += scipy.special.loggamma(2.0) - scipy.special.loggamma(2.0+V1D1+V1D0)\n",
    "    lgM += scipy.special.loggamma(1.0+V1D0) - scipy.special.loggamma(1.0)\n",
    "    lgM += scipy.special.loggamma(1.0+V1D1) - scipy.special.loggamma(1.0)\n",
    "    if variants.ndim == 1:\n",
    "        lgM = lgM.reshape(1,lgM.shape[0]) # lgM is #traits x 1\n",
    "        \n",
    "    return(lgM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GDsearch_all(traits,variants): \n",
    "    ## Get all the stats for all the variants in any given population for multiple traits; particulary used for the entire population\n",
    "    ## Get the nxk matrix of traits==0 and the nxk matrix of traits==1 (n,#subjects;k,#traits)\n",
    "    ## if no individuals are in V0 group when the passed variants is [], the V0D0 counts as well as lgM will be 0.\n",
    "    bpMask0 = traits==0\n",
    "    bpMask0 = bpMask0.astype(np.int16)\n",
    "    d0 = np.sum(bpMask0)\n",
    "    bpMask1 = traits==1\n",
    "    bpMask1 = bpMask1.astype(np.int16)\n",
    "    d1 = np.sum(bpMask1)\n",
    "    ### Get the mxn vector of snp==0 and the mxn vector of snp==1\n",
    "    snpMask0 = variants==0\n",
    "    snpMask0 = snpMask0.astype(np.int16)\n",
    "    snpMask1 = variants==1\n",
    "    snpMask1 = snpMask1.astype(np.int16)\n",
    "    ### Get the four mx1 vector as below: m is # of SNPs in the dataset; for each SNP, the corresponding 4 values \n",
    "    ### from the 4 vectors make up the 2x2 tables between SNP and hypertension\n",
    "    V0D0 = snpMask0@bpMask0\n",
    "    V1D0 = snpMask1@bpMask0\n",
    "    V0D1 = snpMask0@bpMask1\n",
    "    V1D1 = snpMask1@bpMask1\n",
    "    # GiVen the Dirichlet Distributions we are using, the expectation of these conDitional probabilities is as follows:\n",
    "    cp_D1V1 = (1 + V1D1)/(2 + V1D1 + V1D0)*1.0 # P(D=1|V=1) = (alpha11 + V1D1)/(alpha1 + V1D1 + V1D0)*1.0                   \n",
    "    cp_D1V0 = (1 + V0D1)/(2 + V0D1 + V0D0)*1.0  #P(D=1|V=0) = (alpha01 + V0D1)/(alpha0 + V0D1 + V0D0)*1.0              \n",
    "    RR = cp_D1V1/cp_D1V0 #RR is risk ratio; OR is oDDs ratio\n",
    "    # Calculate the log Marginal LikelihooD for this particular SNP based on the collected counts and equation 5 in the worD file\n",
    "    # when j=0 (V=0)\n",
    "    lgM = scipy.special.loggamma(2.0) - scipy.special.loggamma(2.0+V0D1+V0D0)\n",
    "    lgM += scipy.special.loggamma(1.0+V0D0) - scipy.special.loggamma(1.0)\n",
    "    lgM += scipy.special.loggamma(1.0+V0D1) - scipy.special.loggamma(1.0)\n",
    "    # when j=1 (V=1)\n",
    "    lgM += scipy.special.loggamma(2.0) - scipy.special.loggamma(2.0+V1D1+V1D0)\n",
    "    lgM += scipy.special.loggamma(1.0+V1D0) - scipy.special.loggamma(1.0)\n",
    "    lgM += scipy.special.loggamma(1.0+V1D1) - scipy.special.loggamma(1.0)\n",
    "    if variants.ndim == 1:\n",
    "        lgM = lgM.reshape(1,lgM.shape[0]) # lgM is #traits x 1\n",
    "    max_value = np.max(lgM,axis=0) # get the max and index for each row of trait along the column of the 2-D array\n",
    "    max_index = np.argmax(lgM,axis=0)\n",
    "    \n",
    "    return (RR,lgM,max_value,max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgMcal(varID): ## use DriverSearch for V0 and SD_lgM_V1 for V1\n",
    "    i = varIDs.index(varID) #when varIDs is used in the last paralleing code\n",
    "    index1 = variants[i,:]==1\n",
    "    index0 = variants[i,:]==0\n",
    "    V1 = variants[:,index1]\n",
    "    V0 = variants[:,index0] # V0 will be [] and its shape will be (0,) if index0 is all false\n",
    "    BP_V1 = traits[index1] \n",
    "    BP_V0 = traits[index0] \n",
    "    lgMv1_SD = DriverSearch(BP_V1,variants[i,index1])[0] \n",
    "    lgMv0 = DriverSearch(BP_V0,V0) #lgM_v0 is the 2D array containing the lgM for all the variants (row) for all the different traits (column)\n",
    "    lgMv0_sGD = np.max(lgMv0,axis=0) # get the max and index for each row of trait along the column of the 2-D array\n",
    "    sGD_index = np.argmax(lgMv0,axis=0)          \n",
    "    sGD = []\n",
    "    for item in sGD_index:\n",
    "        sGD.append(varIDs[item])\n",
    "    sGD = np.array(sGD)\n",
    "    lgMv0_topGD = []\n",
    "    r = []\n",
    "    k=0\n",
    "    for j in topGD_index: # topGD_index is a global variable obtained outside this function\n",
    "        lgMv0_topGD.append(lgMv0[j,k])\n",
    "        r1 = stats.spearmanr(variants[i,:],variants[j,:])[0]\n",
    "        r.append(r1)\n",
    "        k = k + 1\n",
    "    lgMv0_topGD = np.array(lgMv0_topGD)\n",
    "    r = np.array(r)\n",
    "    lgM_v1v0 = lgMv1_SD + lgMv0_sGD\n",
    "    \n",
    "    return(lgMv1_SD, lgMv0_sGD, lgMv0_topGD, lgM_v1v0, sGD, r, i, varID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgMcal_1(varID): ## use DriverSearch for V0 and SD_lgM_V1 for V1 ## designed for using one topGD\n",
    "    i = varIDs.index(varID) #when varIDs is used in the last paralleing code\n",
    "    index1 = variants[i,:]==1\n",
    "    index0 = variants[i,:]==0\n",
    "    V1 = variants[:,index1]\n",
    "    if use_oneTopGD:\n",
    "        V0 = variants[topGD_index][:,index0] # we will only consider and search over all the unique topGDs from all the traits; #thus one topGD for trait1 may be selected as the sGD for trait2.\n",
    "    else:\n",
    "        V0 = variants[:,index0] # V0 will be [] and its shape will be (0,) if index0 is all false\n",
    "    BP_V1 = traits[index1] \n",
    "    BP_V0 = traits[index0]\n",
    "    lgMv1_SD = DriverSearch(BP_V1,variants[i,index1])[0]\n",
    "    lgMv0 = DriverSearch(BP_V0,V0) #lgM_v0 is the 2D array containing the lgM for all the variants (row) for all the different traits (column)\n",
    "    lgMv0_topGD = [] # collect the lgMv0_topGD for each trait in a 1D array; the lgM value for V0 group when using topGD as the driver\n",
    "    r = []           # collect the r between SD and topGD for each trait in a 1D array\n",
    "    if use_oneTopGD:\n",
    "        for m in range(0,len(traitIDs)):\n",
    "            lgMv0_topGD.append(lgMv0[m,m])\n",
    "        for j in topGD_index: # topGD_index is a global variable obtained outside this function\n",
    "            r1 = stats.spearmanr(variants[i,:],variants[j,:])[0]\n",
    "            r.append(r1)\n",
    "        lgMv0_sGD = np.zeros(len(traitIDs))\n",
    "        sGD = np.zeros(len(traitIDs))\n",
    "    else:\n",
    "        lgMv0_sGD = np.max(lgMv0,axis=0) # get the max and index for each row of trait along the column of the 2-D array\n",
    "        sGD_index = np.argmax(lgMv0,axis=0)          \n",
    "        sGD = [] # collect the sGD for each trait in a 1D array\n",
    "        for item in sGD_index:\n",
    "            sGD.append(varIDs[item])\n",
    "        sGD = np.array(sGD) \n",
    "        k=0  # collect the lgMv0_topGD and r for each trait in a 1D array specifically \n",
    "        for j in topGD_index: \n",
    "            lgMv0_topGD.append(lgMv0[j,k]) \n",
    "            r1 = stats.spearmanr(variants[i,:],variants[j,:])[0]\n",
    "            r.append(r1)\n",
    "            k = k + 1 \n",
    "    lgMv0_topGD = np.array(lgMv0_topGD) \n",
    "    r = np.array(r) \n",
    "    lgM_v1v0 = lgMv1_SD + lgMv0_sGD\n",
    "    \n",
    "    return(lgMv1_SD, lgMv0_sGD, lgMv0_topGD, lgM_v1v0, sGD, r, i, varID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
